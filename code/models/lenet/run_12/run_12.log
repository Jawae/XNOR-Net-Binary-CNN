No data augmentation with noise added in training
****************************************************************
		LeNet on MNIST		
****************************************************************
Net(
  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
  (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
  (xnor2): MultiplicationWithXNOR(
    (signum1): Signum(
      (mean): Mean()
      (arelu1): AffineReLU(
        (relu): ReLU()
      )
      (arelu2): AffineReLU(
        (relu): ReLU()
      )
      (arelu3): AffineReLU(
        (relu): ReLU()
      )
    )
    (beta): BetaVector(
      (mean_vector): MeanVector()
    )
    (mul1): ExpandAndMultiply()
    (signum2): Signum(
      (mean): Mean()
      (arelu1): AffineReLU(
        (relu): ReLU()
      )
      (arelu2): AffineReLU(
        (relu): ReLU()
      )
      (arelu3): AffineReLU(
        (relu): ReLU()
      )
    )
    (alpha): AlphaVector(
      (mean_vector): MeanVector()
    )
    (mul2): ExpandAndMultiply()
    (bn): BatchNorm2d(20, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    (conv): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
    (relu): ReLU(inplace)
  )
  (max2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (fc1): Linear(in_features=800, out_features=500, bias=True)
  (xnor3): MultiplicationWithXNOR(
    (signum1): Signum(
      (mean): Mean()
      (arelu1): AffineReLU(
        (relu): ReLU()
      )
      (arelu2): AffineReLU(
        (relu): ReLU()
      )
      (arelu3): AffineReLU(
        (relu): ReLU()
      )
    )
    (beta): BetaVector(
      (mean_vector): MeanVector()
    )
    (mul1): ExpandAndMultiply()
    (signum2): Signum(
      (mean): Mean()
      (arelu1): AffineReLU(
        (relu): ReLU()
      )
      (arelu2): AffineReLU(
        (relu): ReLU()
      )
      (arelu3): AffineReLU(
        (relu): ReLU()
      )
    )
    (alpha): AlphaVector(
      (mean_vector): MeanVector()
    )
    (mul2): ExpandAndMultiply()
    (bn): BatchNorm1d(800, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)
    (conv): Linear(in_features=800, out_features=500, bias=True)
    (relu): ReLU(inplace)
  )
  (fc2_bn): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (fc2_drop): Dropout(p=0.5)
  (fc2): Linear(in_features=500, out_features=10, bias=True)
)
****************************************************************
		Optimisation Parameters		
****************************************************************
Batch Size    = 128
Learning Rate = 0.010
Momentum      = 0.90
Weight Decay  = 0.000010
Step Size     = 30
Step Gamma    = 0.10
Total Epochs  = 60


Test Epoch 1, loss 0.1318, Accuracy 96.32%
Test Epoch 2, loss 0.1010, Accuracy 97.06%
Test Epoch 3, loss 0.0887, Accuracy 97.39%
Test Epoch 4, loss 0.0807, Accuracy 97.58%
Test Epoch 5, loss 0.0748, Accuracy 97.75%
Test Epoch 6, loss 0.0707, Accuracy 97.84%
Test Epoch 7, loss 0.0666, Accuracy 97.94%
Test Epoch 8, loss 0.0647, Accuracy 98.03%
Test Epoch 9, loss 0.0647, Accuracy 98.00%
Test Epoch 10, loss 0.0613, Accuracy 98.08%
Test Epoch 11, loss 0.0600, Accuracy 98.08%
Test Epoch 12, loss 0.0599, Accuracy 98.18%
Test Epoch 13, loss 0.0565, Accuracy 98.19%
Test Epoch 14, loss 0.0563, Accuracy 98.27%
Test Epoch 15, loss 0.0557, Accuracy 98.27%
Test Epoch 16, loss 0.0536, Accuracy 98.33%
Test Epoch 17, loss 0.0527, Accuracy 98.28%
Test Epoch 18, loss 0.0529, Accuracy 98.34%
Test Epoch 19, loss 0.0536, Accuracy 98.32%
Test Epoch 20, loss 0.0516, Accuracy 98.43%
Test Epoch 21, loss 0.0522, Accuracy 98.34%
Test Epoch 22, loss 0.0506, Accuracy 98.42%
Test Epoch 23, loss 0.0508, Accuracy 98.30%
Test Epoch 24, loss 0.0507, Accuracy 98.43%
Test Epoch 25, loss 0.0493, Accuracy 98.38%
Test Epoch 26, loss 0.0486, Accuracy 98.45%
Test Epoch 27, loss 0.0484, Accuracy 98.50%
Test Epoch 28, loss 0.0480, Accuracy 98.50%
Test Epoch 29, loss 0.0467, Accuracy 98.57%
Test Epoch 30, loss 0.0467, Accuracy 98.59%
Test Epoch 31, loss 0.0453, Accuracy 98.57%
Test Epoch 32, loss 0.0456, Accuracy 98.59%
Test Epoch 33, loss 0.0454, Accuracy 98.55%
Test Epoch 34, loss 0.0448, Accuracy 98.52%
Test Epoch 35, loss 0.0453, Accuracy 98.59%
Test Epoch 36, loss 0.0451, Accuracy 98.56%
Test Epoch 37, loss 0.0450, Accuracy 98.61%
Test Epoch 38, loss 0.0448, Accuracy 98.50%
Test Epoch 39, loss 0.0448, Accuracy 98.57%
Test Epoch 40, loss 0.0453, Accuracy 98.56%
Test Epoch 41, loss 0.0453, Accuracy 98.59%
Test Epoch 42, loss 0.0456, Accuracy 98.63%
Test Epoch 43, loss 0.0447, Accuracy 98.58%
Test Epoch 44, loss 0.0450, Accuracy 98.55%
Test Epoch 45, loss 0.0454, Accuracy 98.52%
Test Epoch 46, loss 0.0448, Accuracy 98.50%
Test Epoch 47, loss 0.0449, Accuracy 98.55%
Test Epoch 48, loss 0.0456, Accuracy 98.59%
Test Epoch 49, loss 0.0453, Accuracy 98.63%
Test Epoch 50, loss 0.0450, Accuracy 98.60%
Test Epoch 51, loss 0.0447, Accuracy 98.60%
Test Epoch 52, loss 0.0451, Accuracy 98.55%
Test Epoch 53, loss 0.0454, Accuracy 98.55%
Test Epoch 54, loss 0.0452, Accuracy 98.60%
Test Epoch 55, loss 0.0453, Accuracy 98.58%
Test Epoch 56, loss 0.0451, Accuracy 98.56%
Test Epoch 57, loss 0.0446, Accuracy 98.55%
Test Epoch 58, loss 0.0450, Accuracy 98.59%
Test Epoch 59, loss 0.0447, Accuracy 98.55%
Test Epoch 60, loss 0.0449, Accuracy 98.61%
